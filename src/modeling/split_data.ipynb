{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up environment\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import some necessary libraries of the usual suspects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science libraries\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn libraries\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\GitHub\\CameraTrap-Animal-Classification')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the train and test CSVs first and see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = r'C:\\GitHub\\CameraTrap-Animal-Classification\\data\\raw'\n",
    "dataset_path = 'data/raw'\n",
    "os.makedirs(dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(os.path.join(dataset_path, 'train_features.csv'), index_col=\"id\")\n",
    "test_features = pd.read_csv(os.path.join(dataset_path, 'test_features.csv'), index_col=\"id\")\n",
    "train_labels = pd.read_csv(os.path.join(dataset_path, 'train_labels.csv'), index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files: train: 16488 test: 4464\n"
     ]
    }
   ],
   "source": [
    "train_features_images = [f for f in os.listdir(os.path.join(dataset_path, 'train_features')) if f.endswith('.jpg')]\n",
    "test_features_images = [f for f in os.listdir(os.path.join(dataset_path, 'test_features')) if f.endswith('.jpg')]\n",
    "\n",
    "print(\"Number of image files: train: {} test: {}\".format(len(train_features_images), len(test_features_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store a sorted list of the labels, so that we can sort the inputs and outputs to our model in a consistent way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n"
     ]
    }
   ],
   "source": [
    "species_labels = sorted(train_labels.columns.unique())\n",
    "print(species_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split data into train and validation sets\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need to split the images in train_features folder into train and validation sets. We'll put aside 20% of the data for evaluation and stratify by the target labels to ensure we have similar relative frequencies of each class in the train and validation sets.\n",
    "\n",
    "You can feel free to adjust `frac` or remove it entirely if you want to run the training on the another set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = ['train', 'validation']\n",
    "classes = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "\n",
    "for subset in subsets:\n",
    "    for class_name in classes:\n",
    "        os.makedirs(os.path.join(dataset_path, subset, class_name), exist_ok=True)\n",
    "\n",
    "train_features_dir = os.path.join(dataset_path, 'train_features')\n",
    "test_features_dir = os.path.join(dataset_path, 'test_features')\n",
    "train_labels = pd.read_csv(os.path.join(dataset_path, 'train_labels.csv'), index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segregation of the images in the train_features folder by copying them to the species subfolders of the same folder (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to segregate images into 8 class in folders: train_features\n",
    "# def segregate_images(src_dir, dest_dir):\n",
    "\n",
    "#     for img_id, row in dest_dir.iterrows():\n",
    "\n",
    "#         img_id = row.name  # Assuming 'id' is the index of the dataframe\n",
    "#         img_file = f\"{img_id}.jpg\"  # Ensure the file extension matches your dataset\n",
    "#         src_path = os.path.join(src_dir, img_file)\n",
    "\n",
    "#         if not os.path.exists(src_path):\n",
    "#             print(f\"Image {img_file} does not exist in the source directory.\")\n",
    "#             continue\n",
    "\n",
    "#         # Copy image to the specific class folder based on binary class columns\n",
    "#         for species in classes:\n",
    "#             if row[species] == 1.0:\n",
    "#                 specific_dest_path = os.path.join(src_dir, species, img_file)\n",
    "\n",
    "#                 if src_path != specific_dest_path:\n",
    "#                     shutil.copy(src_path, specific_dest_path)\n",
    "#                 break\n",
    "\n",
    "# segregate_images(train_features_dir, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First function to clear directory before use, second function to copy images from variables (x_train, x_val, y_train, y_val) after split to folders: train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear the contents of a directory\n",
    "def clear_directory(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "clear_directory(os.path.join(dataset_path, 'train'))\n",
    "clear_directory(os.path.join(dataset_path, 'validation'))\n",
    "\n",
    "\n",
    "# Function to copy images to directory\n",
    "def copy_images(x_df, y_df, dest_dir):\n",
    "\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over the indices of x_df which should match y_df\n",
    "    for idx in x_df.index:\n",
    "        # Construct full image path from the base directory and the filepath in the DataFrame\n",
    "        image_path = os.path.join(dataset_path, x_df.loc[idx, 'filepath'])\n",
    "\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(f\"Image {image_path} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Identify the class label by finding the column with value 1 (assumes one-hot encoding)\n",
    "        class_label = y_df.loc[idx].idxmax()\n",
    "        # Specific destination path for the class within the designated train, validation directory\n",
    "        class_dir = os.path.join(dest_dir, class_label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        # Destination file paths\n",
    "        class_dest_path = os.path.join(class_dir, os.path.basename(image_path))\n",
    "        # Check if the file already exists in the class-specific directory\n",
    "        if not os.path.isfile(class_dest_path):\n",
    "            # Copy the image to the class-specific directory\n",
    "            shutil.copy(image_path, class_dest_path)\n",
    "\n",
    "        # # Create general destination file path to copy images\n",
    "        # general_dest_path = os.path.join(dest_dir, os.path.basename(image_path))\n",
    "\n",
    "        # if not os.path.isfile(general_dest_path):\n",
    "        #     # Copy the image to the general destination directory (optional if only class-specific folders are needed)\n",
    "        #     shutil.copy(image_path, general_dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac = 1\n",
    "# y = train_labels.sample(frac=frac, random_state=42)\n",
    "# x = train_features.loc[y.index].filepath.to_frame()\n",
    "\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "# # Copy new data from split variables to folders\n",
    "# copy_images(x_train, y_train, os.path.join(dataset_path, 'train'))\n",
    "# copy_images(x_val, y_val, os.path.join(dataset_path, 'validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing iteration 1/5\n",
      "Iteration 1\n",
      "\n",
      "Number of training samples: 13190\n",
      "Number of validation samples: 3298\n",
      "Total samples: 16488\n",
      "Actual training ratio: 0.80 (should be 0.80)\n",
      "Actual validation ratio: 0.20 (should be 0.20)\n",
      "Mean difference: 0.0125\n",
      "\n",
      "Species percentages by split:\n",
      "                  train  val\n",
      "monkey_prosimian     15   15\n",
      "antelope_duiker      15   15\n",
      "civet_genet          14   14\n",
      "leopard              13   13\n",
      "blank                13   13\n",
      "rodent               12   12\n",
      "bird                  9    9\n",
      "hog                   5    5\n",
      "\n",
      "Processing iteration 2/5\n",
      "Iteration 2\n",
      "\n",
      "Number of training samples: 13190\n",
      "Number of validation samples: 3298\n",
      "Total samples: 16488\n",
      "Actual training ratio: 0.80 (should be 0.80)\n",
      "Actual validation ratio: 0.20 (should be 0.20)\n",
      "Mean difference: 0.0147\n",
      "\n",
      "Species percentages by split:\n",
      "                  train  val\n",
      "monkey_prosimian     15   15\n",
      "antelope_duiker      15   15\n",
      "civet_genet          14   14\n",
      "leopard              13   13\n",
      "blank                13   13\n",
      "rodent               12   12\n",
      "bird                  9    9\n",
      "hog                   5    5\n",
      "\n",
      "Processing iteration 3/5\n",
      "Iteration 3\n",
      "\n",
      "Number of training samples: 13190\n",
      "Number of validation samples: 3298\n",
      "Total samples: 16488\n",
      "Actual training ratio: 0.80 (should be 0.80)\n",
      "Actual validation ratio: 0.20 (should be 0.20)\n",
      "Mean difference: 0.0128\n",
      "\n",
      "Species percentages by split:\n",
      "                  train  val\n",
      "monkey_prosimian     15   15\n",
      "antelope_duiker      15   15\n",
      "civet_genet          14   14\n",
      "leopard              13   13\n",
      "blank                13   13\n",
      "rodent               12   12\n",
      "bird                  9    9\n",
      "hog                   5    5\n",
      "\n",
      "Processing iteration 4/5\n",
      "Iteration 4\n",
      "\n",
      "Number of training samples: 13191\n",
      "Number of validation samples: 3297\n",
      "Total samples: 16488\n",
      "Actual training ratio: 0.80 (should be 0.80)\n",
      "Actual validation ratio: 0.20 (should be 0.20)\n",
      "Mean difference: 0.0161\n",
      "\n",
      "Species percentages by split:\n",
      "                  train  val\n",
      "monkey_prosimian     15   15\n",
      "antelope_duiker      15   15\n",
      "civet_genet          14   14\n",
      "leopard              13   13\n",
      "blank                13   13\n",
      "rodent               12   12\n",
      "bird                  9    9\n",
      "hog                   5    5\n",
      "\n",
      "Processing iteration 5/5\n",
      "Iteration 5\n",
      "\n",
      "Number of training samples: 13191\n",
      "Number of validation samples: 3297\n",
      "Total samples: 16488\n",
      "Actual training ratio: 0.80 (should be 0.80)\n",
      "Actual validation ratio: 0.20 (should be 0.20)\n",
      "Mean difference: 0.0219\n",
      "\n",
      "Species percentages by split:\n",
      "                  train  val\n",
      "monkey_prosimian     15   15\n",
      "antelope_duiker      15   14\n",
      "civet_genet          14   14\n",
      "leopard              13   13\n",
      "blank                13   13\n",
      "rodent               12   12\n",
      "bird                  9    9\n",
      "hog                   5    5\n",
      "\n",
      "The best iteration is iteration 1 with a mean difference of 0.0125\n"
     ]
    }
   ],
   "source": [
    "frac = 1\n",
    "y = train_labels.sample(frac=frac, random_state=42)\n",
    "x = train_features.loc[y.index].filepath.to_frame()\n",
    "\n",
    "# Setting the split ratio\n",
    "test_size = 0.2  # 80/20 split\n",
    "n_splits = int(1 / test_size)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize variables to store fold data\n",
    "fold_data = {f\"fold_{i+1}\": {\"x_train\": [], \"y_train\": [], \"x_val\": [], \"y_val\": []} for i in range(n_splits)}\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "# Using StratifiedKFold to create folds and calculate proportions\n",
    "for iteration, (train_index, val_index) in enumerate(skf.split(x, y.idxmax(axis=1)), start=1):\n",
    "    print(f\"\\nProcessing iteration {iteration}/{n_splits}\")\n",
    "\n",
    "    x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Storing data for the current iteration\n",
    "    fold_data[f\"fold_{iteration}\"][\"x_train\"] = x_train\n",
    "    fold_data[f\"fold_{iteration}\"][\"y_train\"] = y_train\n",
    "    fold_data[f\"fold_{iteration}\"][\"x_val\"] = x_val\n",
    "    fold_data[f\"fold_{iteration}\"][\"y_val\"] = y_val\n",
    "\n",
    "    # Class proportions in training and validation sets\n",
    "    train_distribution = y_train.sum()\n",
    "    val_distribution = y_val.sum()\n",
    "\n",
    "    train_proportion = train_distribution / len(y_train) * 100\n",
    "    val_proportion = val_distribution / len(y_val) * 100\n",
    "\n",
    "    fold_results.append((train_proportion, val_proportion))\n",
    "\n",
    "    differences = np.abs(train_proportion - val_proportion)\n",
    "    mean_difference = differences.mean()\n",
    "\n",
    "    # Debugging and verification for the splits\n",
    "    num_train = len(x_train)\n",
    "    num_val = len(x_val)\n",
    "    total = num_train + num_val\n",
    "    actual_train_ratio = num_train / total\n",
    "    actual_val_ratio = num_val / total\n",
    "\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    print(f\"\\nNumber of training samples: {num_train}\")\n",
    "    print(f\"Number of validation samples: {num_val}\")\n",
    "    print(f\"Total samples: {total}\")\n",
    "    print(f\"Actual training ratio: {actual_train_ratio:.2f} (should be {1 - test_size:.2f})\")\n",
    "    print(f\"Actual validation ratio: {actual_val_ratio:.2f} (should be {test_size:.2f})\")\n",
    "    print(f\"Mean difference: {mean_difference:.4f}\")\n",
    "    print()\n",
    "\n",
    "    split_pcts = pd.DataFrame(\n",
    "        {\n",
    "            \"train\": y_train.idxmax(axis=1).value_counts(normalize=True),\n",
    "            \"val\": y_val.idxmax(axis=1).value_counts(normalize=True),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Species percentages by split:\")\n",
    "    print((split_pcts.fillna(0) * 100).astype(int))\n",
    "\n",
    "    train_std = split_pcts['train'].std()\n",
    "    val_std = split_pcts['val'].std()\n",
    "    score = train_std + val_std\n",
    "\n",
    "# Calculating the average difference in proportions for each split\n",
    "mean_differences = []\n",
    "\n",
    "for iteration, (train_proportion, val_proportion) in enumerate(fold_results, start=1):\n",
    "    differences = np.abs(train_proportion - val_proportion)\n",
    "    mean_difference = differences.mean()\n",
    "    mean_differences.append(mean_difference)\n",
    "\n",
    "best_fold_index = np.argmin(mean_differences)\n",
    "print(f\"\\nThe best iteration is iteration {best_fold_index + 1} with a mean difference of {mean_differences[best_fold_index]:.4f}\")\n",
    "\n",
    "# Selecting the best split\n",
    "best_fold_key = f\"fold_{best_fold_index + 1}\"\n",
    "x_train = fold_data[best_fold_key][\"x_train\"]\n",
    "y_train = fold_data[best_fold_key][\"y_train\"]\n",
    "x_val = fold_data[best_fold_key][\"x_val\"]\n",
    "y_val = fold_data[best_fold_key][\"y_val\"]\n",
    "\n",
    "clear_directory(os.path.join(dataset_path, 'train'))\n",
    "clear_directory(os.path.join(dataset_path, 'validation'))\n",
    "\n",
    "copy_images(x_train, y_train, os.path.join(dataset_path, 'train'))\n",
    "copy_images(x_val, y_val, os.path.join(dataset_path, 'validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedGroup K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sampling a fraction of the data for stratification and setting up the file paths for the corresponding labels\n",
    "# frac = 1\n",
    "# y = train_labels.sample(frac=frac, random_state=42)\n",
    "# x = train_features.loc[y.index].filepath.to_frame()\n",
    "\n",
    "# # Preparing lists of necessary features for StratifiedGroupKFold: site, sample IDs, and class labels\n",
    "# list_of_sites = train_features.loc[y.index]['site'].tolist()\n",
    "# list_of_ids = train_features.loc[y.index].index.tolist()\n",
    "# list_of_class_numbers = y.idxmax(axis=1).astype('category').cat.codes.tolist()\n",
    "\n",
    "# # Define the test set proportion and calculate the number of folds for StratifiedGroupKFold\n",
    "# test_size = 0.2\n",
    "# n_splits = int(1 / test_size)\n",
    "\n",
    "# # Initialize StratifiedGroupKFold for creating splits based on stratification criteria\n",
    "# sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "# # Generate stratified train/validation splits\n",
    "# iteration_splits = list(sgkf.split(list_of_ids, list_of_class_numbers, list_of_sites))\n",
    "\n",
    "# # Create a dictionary to store train/validation data for each fold\n",
    "# fold_data = {f\"fold_{i+1}\": {\"x_train\": [], \"y_train\": [], \"x_val\": [], \"y_val\": []} for i in range(n_splits)}\n",
    "\n",
    "# # Iterate through the splits, process each fold, and store results for later evaluation\n",
    "# fold_results = []\n",
    "# for iteration, (train_idx, val_idx) in enumerate(iteration_splits, start=1):\n",
    "#     # Extracting train and validation IDs for the current fold\n",
    "#     train_ids = [list_of_ids[i] for i in train_idx]\n",
    "#     val_ids = [list_of_ids[i] for i in val_idx]\n",
    "\n",
    "#     # Prepare train and validation datasets based on the current split\n",
    "#     x_train = train_features.loc[train_ids]\n",
    "#     y_train = train_labels.loc[train_ids]\n",
    "#     x_val = train_features.loc[val_ids]\n",
    "#     y_val = train_labels.loc[val_ids]\n",
    "\n",
    "#     # Storing the split data for later access\n",
    "#     fold_data[f\"fold_{iteration}\"][\"x_train\"] = x_train\n",
    "#     fold_data[f\"fold_{iteration}\"][\"y_train\"] = y_train\n",
    "#     fold_data[f\"fold_{iteration}\"][\"x_val\"] = x_val\n",
    "#     fold_data[f\"fold_{iteration}\"][\"y_val\"] = y_val\n",
    "\n",
    "#     # Evaluate class distribution for both train and validation sets\n",
    "#     train_distribution = y_train.sum()\n",
    "#     val_distribution = y_val.sum()\n",
    "\n",
    "#     # Compute the percentage representation of each class in train and validation datasets\n",
    "#     train_proportion = train_distribution / len(y_train) * 100\n",
    "#     val_proportion = val_distribution / len(y_val) * 100\n",
    "\n",
    "#     fold_results.append((train_proportion, val_proportion))\n",
    "\n",
    "#     # Calculate the mean difference in class distribution between train and validation\n",
    "#     differences = np.abs(train_proportion - val_proportion)\n",
    "#     mean_difference = differences.mean()\n",
    "\n",
    "#     # Debug: Validate the sample count and proportions in the split\n",
    "#     num_train = len(x_train)\n",
    "#     num_val = len(x_val)\n",
    "#     total = num_train + num_val\n",
    "#     actual_train_ratio = num_train / total\n",
    "#     actual_val_ratio = num_val / total\n",
    "\n",
    "#     print(f\"Iteration {iteration}\")\n",
    "#     print(f\"Number of training samples: {num_train}\")\n",
    "#     print(f\"Number of validation samples: {num_val}\")\n",
    "#     print(f\"Total samples: {total}\")\n",
    "#     print(f\"Actual train ratio: {actual_train_ratio:.2f} (should be {1 - test_size})\")\n",
    "#     print(f\"Actual validation ratio: {actual_val_ratio:.2f} (should be {test_size})\")\n",
    "#     print(f\"Mean difference: {mean_difference:.4f}\")\n",
    "#     print()\n",
    "\n",
    "#     # Display the class distribution percentages for both train and validation sets\n",
    "#     split_pcts = pd.DataFrame(\n",
    "#         {\n",
    "#             \"train\": y_train.idxmax(axis=1).value_counts(normalize=True),\n",
    "#             \"val\": y_val.idxmax(axis=1).value_counts(normalize=True),\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     print(\"Species percentages by split:\\n\")\n",
    "#     print((split_pcts.fillna(0) * 100).astype(int))\n",
    "\n",
    "#     # Calculate and score the split based on class distribution variance\n",
    "#     train_std = split_pcts['train'].std()\n",
    "#     val_std = split_pcts['val'].std()\n",
    "#     score = train_std + val_std\n",
    "\n",
    "# # Post-process: Calculate mean differences for all splits and select the best one based on minimal difference\n",
    "# mean_differences = []\n",
    "# for iteration, (train_proportion, val_proportion) in enumerate(fold_results, start=1):\n",
    "#     differences = np.abs(train_proportion - val_proportion)\n",
    "#     mean_difference = differences.mean()\n",
    "#     mean_differences.append(mean_difference)\n",
    "\n",
    "# best_iteration_index = np.argmin(mean_differences)\n",
    "# print(f\"The best iteration is iteration {best_iteration_index + 1} with a mean difference of {mean_differences[best_iteration_index]:.4f}\")\n",
    "\n",
    "# # Select the best iteration and retrieve the corresponding train/validation datasets\n",
    "# best_iteration_key = f\"fold_{best_iteration_index + 1}\"\n",
    "# x_train = fold_data[best_iteration_key][\"x_train\"]\n",
    "# y_train = fold_data[best_iteration_key][\"y_train\"]\n",
    "# x_val = fold_data[best_iteration_key][\"x_val\"]\n",
    "# y_val = fold_data[best_iteration_key][\"y_val\"]\n",
    "\n",
    "# # Clear any previously stored train and validation data from directories\n",
    "# clear_directory(os.path.join(dataset_path, 'train'))\n",
    "# clear_directory(os.path.join(dataset_path, 'validation'))\n",
    "\n",
    "# # Copy the new train/validation data into the appropriate directories for model training\n",
    "# copy_images(x_train, y_train, os.path.join(dataset_path, 'train'))\n",
    "# copy_images(x_val, y_val, os.path.join(dataset_path, 'validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check for overlap of locations between training and validation sets and lack of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique sites in the training set: 147\n",
      "Number of unique sites in the validation set: 144\n",
      "Total number of unique sites in the dataset: 148\n",
      "\n",
      "Overlap between training and validation sets:\n",
      "Site S0161 appears in both the training and validation sets.\n",
      "Site S0010 appears in both the training and validation sets.\n",
      "Site S0188 appears in both the training and validation sets.\n",
      "Site S0001 appears in both the training and validation sets.\n",
      "Site S0139 appears in both the training and validation sets.\n",
      "Site S0104 appears in both the training and validation sets.\n",
      "Site S0019 appears in both the training and validation sets.\n",
      "Site S0063 appears in both the training and validation sets.\n",
      "Site S0150 appears in both the training and validation sets.\n",
      "Site S0180 appears in both the training and validation sets.\n",
      "Site S0157 appears in both the training and validation sets.\n",
      "Site S0020 appears in both the training and validation sets.\n",
      "Site S0106 appears in both the training and validation sets.\n",
      "Site S0124 appears in both the training and validation sets.\n",
      "Site S0053 appears in both the training and validation sets.\n",
      "Site S0110 appears in both the training and validation sets.\n",
      "Site S0095 appears in both the training and validation sets.\n",
      "Site S0060 appears in both the training and validation sets.\n",
      "Site S0096 appears in both the training and validation sets.\n",
      "Site S0004 appears in both the training and validation sets.\n",
      "Site S0127 appears in both the training and validation sets.\n",
      "Site S0045 appears in both the training and validation sets.\n",
      "Site S0074 appears in both the training and validation sets.\n",
      "Site S0024 appears in both the training and validation sets.\n",
      "Site S0050 appears in both the training and validation sets.\n",
      "Site S0056 appears in both the training and validation sets.\n",
      "Site S0112 appears in both the training and validation sets.\n",
      "Site S0136 appears in both the training and validation sets.\n",
      "Site S0023 appears in both the training and validation sets.\n",
      "Site S0101 appears in both the training and validation sets.\n",
      "Site S0032 appears in both the training and validation sets.\n",
      "Site S0113 appears in both the training and validation sets.\n",
      "Site S0155 appears in both the training and validation sets.\n",
      "Site S0197 appears in both the training and validation sets.\n",
      "Site S0028 appears in both the training and validation sets.\n",
      "Site S0122 appears in both the training and validation sets.\n",
      "Site S0046 appears in both the training and validation sets.\n",
      "Site S0015 appears in both the training and validation sets.\n",
      "Site S0018 appears in both the training and validation sets.\n",
      "Site S0006 appears in both the training and validation sets.\n",
      "Site S0031 appears in both the training and validation sets.\n",
      "Site S0144 appears in both the training and validation sets.\n",
      "Site S0035 appears in both the training and validation sets.\n",
      "Site S0021 appears in both the training and validation sets.\n",
      "Site S0182 appears in both the training and validation sets.\n",
      "Site S0123 appears in both the training and validation sets.\n",
      "Site S0185 appears in both the training and validation sets.\n",
      "Site S0076 appears in both the training and validation sets.\n",
      "Site S0084 appears in both the training and validation sets.\n",
      "Site S0014 appears in both the training and validation sets.\n",
      "Site S0071 appears in both the training and validation sets.\n",
      "Site S0073 appears in both the training and validation sets.\n",
      "Site S0133 appears in both the training and validation sets.\n",
      "Site S0117 appears in both the training and validation sets.\n",
      "Site S0098 appears in both the training and validation sets.\n",
      "Site S0043 appears in both the training and validation sets.\n",
      "Site S0146 appears in both the training and validation sets.\n",
      "Site S0047 appears in both the training and validation sets.\n",
      "Site S0198 appears in both the training and validation sets.\n",
      "Site S0070 appears in both the training and validation sets.\n",
      "Site S0022 appears in both the training and validation sets.\n",
      "Site S0030 appears in both the training and validation sets.\n",
      "Site S0085 appears in both the training and validation sets.\n",
      "Site S0173 appears in both the training and validation sets.\n",
      "Site S0003 appears in both the training and validation sets.\n",
      "Site S0068 appears in both the training and validation sets.\n",
      "Site S0137 appears in both the training and validation sets.\n",
      "Site S0159 appears in both the training and validation sets.\n",
      "Site S0005 appears in both the training and validation sets.\n",
      "Site S0077 appears in both the training and validation sets.\n",
      "Site S0183 appears in both the training and validation sets.\n",
      "Site S0079 appears in both the training and validation sets.\n",
      "Site S0175 appears in both the training and validation sets.\n",
      "Site S0027 appears in both the training and validation sets.\n",
      "Site S0184 appears in both the training and validation sets.\n",
      "Site S0017 appears in both the training and validation sets.\n",
      "Site S0059 appears in both the training and validation sets.\n",
      "Site S0125 appears in both the training and validation sets.\n",
      "Site S0044 appears in both the training and validation sets.\n",
      "Site S0026 appears in both the training and validation sets.\n",
      "Site S0107 appears in both the training and validation sets.\n",
      "Site S0171 appears in both the training and validation sets.\n",
      "Site S0080 appears in both the training and validation sets.\n",
      "Site S0130 appears in both the training and validation sets.\n",
      "Site S0120 appears in both the training and validation sets.\n",
      "Site S0029 appears in both the training and validation sets.\n",
      "Site S0176 appears in both the training and validation sets.\n",
      "Site S0147 appears in both the training and validation sets.\n",
      "Site S0108 appears in both the training and validation sets.\n",
      "Site S0094 appears in both the training and validation sets.\n",
      "Site S0148 appears in both the training and validation sets.\n",
      "Site S0042 appears in both the training and validation sets.\n",
      "Site S0178 appears in both the training and validation sets.\n",
      "Site S0016 appears in both the training and validation sets.\n",
      "Site S0007 appears in both the training and validation sets.\n",
      "Site S0061 appears in both the training and validation sets.\n",
      "Site S0008 appears in both the training and validation sets.\n",
      "Site S0191 appears in both the training and validation sets.\n",
      "Site S0131 appears in both the training and validation sets.\n",
      "Site S0158 appears in both the training and validation sets.\n",
      "Site S0002 appears in both the training and validation sets.\n",
      "Site S0121 appears in both the training and validation sets.\n",
      "Site S0190 appears in both the training and validation sets.\n",
      "Site S0141 appears in both the training and validation sets.\n",
      "Site S0069 appears in both the training and validation sets.\n",
      "Site S0169 appears in both the training and validation sets.\n",
      "Site S0196 appears in both the training and validation sets.\n",
      "Site S0170 appears in both the training and validation sets.\n",
      "Site S0036 appears in both the training and validation sets.\n",
      "Site S0167 appears in both the training and validation sets.\n",
      "Site S0013 appears in both the training and validation sets.\n",
      "Site S0093 appears in both the training and validation sets.\n",
      "Site S0081 appears in both the training and validation sets.\n",
      "Site S0177 appears in both the training and validation sets.\n",
      "Site S0049 appears in both the training and validation sets.\n",
      "Site S0083 appears in both the training and validation sets.\n",
      "Site S0179 appears in both the training and validation sets.\n",
      "Site S0160 appears in both the training and validation sets.\n",
      "Site S0097 appears in both the training and validation sets.\n",
      "Site S0156 appears in both the training and validation sets.\n",
      "Site S0105 appears in both the training and validation sets.\n",
      "Site S0092 appears in both the training and validation sets.\n",
      "Site S0134 appears in both the training and validation sets.\n",
      "Site S0088 appears in both the training and validation sets.\n",
      "Site S0149 appears in both the training and validation sets.\n",
      "Site S0009 appears in both the training and validation sets.\n",
      "Site S0062 appears in both the training and validation sets.\n",
      "Site S0051 appears in both the training and validation sets.\n",
      "Site S0164 appears in both the training and validation sets.\n",
      "Site S0193 appears in both the training and validation sets.\n",
      "Site S0163 appears in both the training and validation sets.\n",
      "Site S0129 appears in both the training and validation sets.\n",
      "Site S0038 appears in both the training and validation sets.\n",
      "Site S0174 appears in both the training and validation sets.\n",
      "Site S0172 appears in both the training and validation sets.\n",
      "Site S0115 appears in both the training and validation sets.\n",
      "Site S0025 appears in both the training and validation sets.\n",
      "Site S0054 appears in both the training and validation sets.\n",
      "Site S0153 appears in both the training and validation sets.\n",
      "Site S0186 appears in both the training and validation sets.\n",
      "Site S0075 appears in both the training and validation sets.\n",
      "Site S0089 appears in both the training and validation sets.\n",
      "Site S0138 appears in both the training and validation sets.\n",
      "\n",
      "No sites are missing from both training and validation sets.\n"
     ]
    }
   ],
   "source": [
    "def check_site_overlap_and_missing_sites(x_train, x_val, train_features):\n",
    "\n",
    "    # Print the sites for debugging purposes\n",
    "    # print(\"Train sites:\\n\", train_sites.value_counts())\n",
    "    # print(\"\\nValidation sites:\\n\", val_sites.value_counts())\n",
    "\n",
    "    # Extract the 'site' column from the train and validation sets\n",
    "    train_sites = train_features.loc[x_train.index]['site']\n",
    "    val_sites = train_features.loc[x_val.index]['site']\n",
    "\n",
    "    # Count the unique sites in training and validation sets\n",
    "    unique_train_sites = set(train_sites)\n",
    "    unique_val_sites = set(val_sites)\n",
    "\n",
    "    # Set of all unique sites in the dataset\n",
    "    all_sites = set(train_features['site'])\n",
    "\n",
    "    # Identify common sites between training and validation sets\n",
    "    common_sites = unique_train_sites.intersection(unique_val_sites)\n",
    "\n",
    "    # Find sites missing from both training and validation sets\n",
    "    missing_sites = all_sites - (unique_train_sites.union(unique_val_sites))\n",
    "\n",
    "    # Output the number of unique sites in each set\n",
    "    print(\"Number of unique sites in the training set:\", len(unique_train_sites))\n",
    "    print(\"Number of unique sites in the validation set:\", len(unique_val_sites))\n",
    "    print(\"Total number of unique sites in the dataset:\", len(all_sites))\n",
    "\n",
    "    # If there are common sites, display them\n",
    "    if common_sites:\n",
    "        print(\"\\nOverlap between training and validation sets:\")\n",
    "        for site in common_sites:\n",
    "            print(f\"Site {site} appears in both the training and validation sets.\")\n",
    "    else:\n",
    "        print(\"\\nNo overlap between training and validation sets.\")\n",
    "\n",
    "    # If there are missing sites, display them\n",
    "    if missing_sites:\n",
    "        print(\"\\nSites that are missing from both training and validation sets:\")\n",
    "        for site in missing_sites:\n",
    "            print(f\"Site {site} is missing from both the training and validation sets.\")\n",
    "    else:\n",
    "        print(\"\\nNo sites are missing from both training and validation sets.\")\n",
    "\n",
    "# Example usage of the function\n",
    "check_site_overlap_and_missing_sites(x_train, x_val, train_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what `x_train` and `y_train` look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZJ008416</th>\n",
       "      <td>train_features/ZJ008416.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009568</th>\n",
       "      <td>train_features/ZJ009568.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ012401</th>\n",
       "      <td>train_features/ZJ012401.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ008603</th>\n",
       "      <td>train_features/ZJ008603.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009236</th>\n",
       "      <td>train_features/ZJ009236.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filepath\n",
       "id                                   \n",
       "ZJ008416  train_features/ZJ008416.jpg\n",
       "ZJ009568  train_features/ZJ009568.jpg\n",
       "ZJ012401  train_features/ZJ012401.jpg\n",
       "ZJ008603  train_features/ZJ008603.jpg\n",
       "ZJ009236  train_features/ZJ009236.jpg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZJ008416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ012401</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ008603</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          antelope_duiker  bird  blank  civet_genet  hog  leopard  \\\n",
       "id                                                                  \n",
       "ZJ008416              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ009568              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ012401              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ008603              1.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ009236              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "\n",
       "          monkey_prosimian  rodent  \n",
       "id                                  \n",
       "ZJ008416               0.0     1.0  \n",
       "ZJ009568               0.0     1.0  \n",
       "ZJ012401               1.0     0.0  \n",
       "ZJ008603               0.0     0.0  \n",
       "ZJ009236               1.0     0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13190, 1), (13190, 8), (3298, 1), (3298, 8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's validate that our split has resulted in roughly similar relative distributions of species across the train and val sets (because of how we passed `stratify=y` above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species percentages by split:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <td>15.12</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antelope_duiker</th>\n",
       "      <td>15.00</td>\n",
       "      <td>15.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civet_genet</th>\n",
       "      <td>14.69</td>\n",
       "      <td>14.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leopard</th>\n",
       "      <td>13.67</td>\n",
       "      <td>13.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blank</th>\n",
       "      <td>13.42</td>\n",
       "      <td>13.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rodent</th>\n",
       "      <td>12.21</td>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hog</th>\n",
       "      <td>5.94</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train    val\n",
       "monkey_prosimian  15.12  15.10\n",
       "antelope_duiker   15.00  15.01\n",
       "civet_genet       14.69  14.71\n",
       "leopard           13.67  13.67\n",
       "blank             13.42  13.43\n",
       "rodent            12.21  12.22\n",
       "bird               9.95   9.95\n",
       "hog                5.94   5.91"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_pcts = pd.DataFrame(\n",
    "    {\n",
    "        \"train\": y_train.idxmax(axis=1).value_counts(normalize=True),\n",
    "        \"val\": y_val.idxmax(axis=1).value_counts(normalize=True),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Species percentages by split:\")\n",
    "(split_pcts.fillna(0) * 100).astype(int)\n",
    "(split_pcts.fillna(0) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>number of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw\\train\\antelope_duiker</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw\\train\\bird</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw\\train\\blank</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/raw\\train\\civet_genet</td>\n",
       "      <td>1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/raw\\train\\hog</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/raw\\train\\leopard</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/raw\\train\\monkey_prosimian</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/raw\\train\\rodent</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             train  number of images\n",
       "0   data/raw\\train\\antelope_duiker              1979\n",
       "1              data/raw\\train\\bird              1313\n",
       "2             data/raw\\train\\blank              1770\n",
       "3       data/raw\\train\\civet_genet              1938\n",
       "4               data/raw\\train\\hog               783\n",
       "5           data/raw\\train\\leopard              1803\n",
       "6  data/raw\\train\\monkey_prosimian              1994\n",
       "7            data/raw\\train\\rodent              1610"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "      <th>number of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw\\validation\\antelope_duiker</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw\\validation\\bird</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw\\validation\\blank</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/raw\\validation\\civet_genet</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/raw\\validation\\hog</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/raw\\validation\\leopard</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/raw\\validation\\monkey_prosimian</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/raw\\validation\\rodent</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             validation  number of images\n",
       "0   data/raw\\validation\\antelope_duiker               495\n",
       "1              data/raw\\validation\\bird               328\n",
       "2             data/raw\\validation\\blank               443\n",
       "3       data/raw\\validation\\civet_genet               485\n",
       "4               data/raw\\validation\\hog               195\n",
       "5           data/raw\\validation\\leopard               451\n",
       "6  data/raw\\validation\\monkey_prosimian               498\n",
       "7            data/raw\\validation\\rodent               403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_features</th>\n",
       "      <th>number of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw\\test_features</td>\n",
       "      <td>4464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test_features  number of images\n",
       "0  data/raw\\test_features              4464"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define dictionaries to hold data for each category\n",
    "data_train = []\n",
    "data_validation = []\n",
    "data_test_features = []\n",
    "\n",
    "# Iterate over each subdirectory\n",
    "for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
    "    # Count number of images in the current directory\n",
    "    num_images = sum(1 for filename in filenames if filename.lower().endswith('.jpg'))\n",
    "    if num_images > 0:\n",
    "        # Check the category of the current directory based on the path\n",
    "        parts = dirpath.split(os.sep)\n",
    "        if \"train\" in parts:\n",
    "            data_train.append({'train': dirpath, 'number of images': num_images})\n",
    "        elif \"validation\" in parts:\n",
    "            data_validation.append({'validation': dirpath, 'number of images': num_images})\n",
    "        elif \"test_features\" in parts:\n",
    "            data_test_features.append({'test_features': dirpath, 'number of images': num_images})\n",
    "\n",
    "# Create DataFrames for each category with the specified column names\n",
    "df_train = pd.DataFrame(data_train)\n",
    "df_validation = pd.DataFrame(data_validation)\n",
    "df_test_features = pd.DataFrame(data_test_features)\n",
    "\n",
    "# Display each sorted DataFrame\n",
    "display(df_train)\n",
    "display(df_validation)\n",
    "display(df_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final file structure after split images look like this:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── train_features/\n",
    "│   ├── ZJ000001.jpg\n",
    "│   └── ...\n",
    "│\n",
    "├── test_features/\n",
    "│   ├── ZJ16488.jpg\n",
    "│   └── ...\n",
    "│\n",
    "├── train/\n",
    "│   ├── antelope_duiker (class 1)/\n",
    "│   │   ├── ZJ000001.jpg\n",
    "│   │   └── ...\n",
    "│   ├── ...\n",
    "│   └── hog (class 8)/\n",
    "│       ├── ZJ000008.jpg\n",
    "│       └── ...\n",
    "│\n",
    "└── validation/\n",
    "    ├── antelope_duiker (class 1)/\n",
    "    │   ├── ZJ000009.jpg\n",
    "    │   └── ...\n",
    "    ├── ...\n",
    "    └── hog (class 8)/\n",
    "        ├── ZJ000016.jpg\n",
    "        └── ...\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
