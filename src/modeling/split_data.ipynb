{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up environment\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import some necessary libraries of the usual suspects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science libraries\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn libraries\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\GitHub\\CameraTrap-Animal-Classification')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the train and test CSVs first and see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = r'C:\\GitHub\\CameraTrap-Animal-Classification\\data\\raw'\n",
    "dataset_path = 'data/raw'\n",
    "os.makedirs(dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(os.path.join(dataset_path, 'train_features.csv'), index_col=\"id\")\n",
    "test_features = pd.read_csv(os.path.join(dataset_path, 'test_features.csv'), index_col=\"id\")\n",
    "train_labels = pd.read_csv(os.path.join(dataset_path, 'train_labels.csv'), index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files: train: 16488 test: 4464\n"
     ]
    }
   ],
   "source": [
    "train_features_images = [f for f in os.listdir(os.path.join(dataset_path, 'train_features')) if f.endswith('.jpg')]\n",
    "test_features_images = [f for f in os.listdir(os.path.join(dataset_path, 'test_features')) if f.endswith('.jpg')]\n",
    "\n",
    "print(\"Number of image files: train: {} test: {}\".format(len(train_features_images), len(test_features_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store a sorted list of the labels, so that we can sort the inputs and outputs to our model in a consistent way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n"
     ]
    }
   ],
   "source": [
    "species_labels = sorted(train_labels.columns.unique())\n",
    "print(species_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split data into train and validation sets\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need to split the images in train_features folder into train and validation sets. We'll put aside 20% of the data for evaluation and stratify by the target labels to ensure we have similar relative frequencies of each class in the train and validation sets.\n",
    "\n",
    "You can feel free to adjust `frac` or remove it entirely if you want to run the training on the another set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = ['train', 'validation']\n",
    "classes = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "\n",
    "for subset in subsets:\n",
    "    for class_name in classes:\n",
    "        os.makedirs(os.path.join(dataset_path, subset, class_name), exist_ok=True)\n",
    "\n",
    "train_features_dir = os.path.join(dataset_path, 'train_features')\n",
    "test_features_dir = os.path.join(dataset_path, 'test_features')\n",
    "train_labels = pd.read_csv(os.path.join(dataset_path, 'train_labels.csv'), index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segregation of the images in the train_features folder by copying them to the species subfolders of the same folder (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to segregate images into 8 class in folders: train_features\n",
    "# def segregate_images(src_dir, dest_dir):\n",
    "\n",
    "#     for img_id, row in dest_dir.iterrows():\n",
    "\n",
    "#         img_id = row.name  # Assuming 'id' is the index of the dataframe\n",
    "#         img_file = f\"{img_id}.jpg\"  # Ensure the file extension matches your dataset\n",
    "#         src_path = os.path.join(src_dir, img_file)\n",
    "\n",
    "#         if not os.path.exists(src_path):\n",
    "#             print(f\"Image {img_file} does not exist in the source directory.\")\n",
    "#             continue\n",
    "\n",
    "#         # Copy image to the specific class folder based on binary class columns\n",
    "#         for species in classes:\n",
    "#             if row[species] == 1.0:\n",
    "#                 specific_dest_path = os.path.join(src_dir, species, img_file)\n",
    "\n",
    "#                 if src_path != specific_dest_path:\n",
    "#                     shutil.copy(src_path, specific_dest_path)\n",
    "#                 break\n",
    "\n",
    "# segregate_images(train_features_dir, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First function to clear directory before use, second function to copy images from variables (x_train, x_val, y_train, y_val) after split to folders: train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear the contents of a directory\n",
    "def clear_directory(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "clear_directory(os.path.join(dataset_path, 'train'))\n",
    "clear_directory(os.path.join(dataset_path, 'validation'))\n",
    "\n",
    "\n",
    "# Function to copy images to directory\n",
    "def copy_images(x_df, y_df, dest_dir):\n",
    "\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over the indices of x_df which should match y_df\n",
    "    for idx in x_df.index:\n",
    "        # Construct full image path from the base directory and the filepath in the DataFrame\n",
    "        image_path = os.path.join(dataset_path, x_df.loc[idx, 'filepath'])\n",
    "\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(f\"Image {image_path} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Identify the class label by finding the column with value 1 (assumes one-hot encoding)\n",
    "        class_label = y_df.loc[idx].idxmax()\n",
    "        # Specific destination path for the class within the designated train, validation directory\n",
    "        class_dir = os.path.join(dest_dir, class_label)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        # Destination file paths\n",
    "        class_dest_path = os.path.join(class_dir, os.path.basename(image_path))\n",
    "        # Check if the file already exists in the class-specific directory\n",
    "        if not os.path.isfile(class_dest_path):\n",
    "            # Copy the image to the class-specific directory\n",
    "            shutil.copy(image_path, class_dest_path)\n",
    "\n",
    "        # # Create general destination file path to copy images\n",
    "        # general_dest_path = os.path.join(dest_dir, os.path.basename(image_path))\n",
    "\n",
    "        # if not os.path.isfile(general_dest_path):\n",
    "        #     # Copy the image to the general destination directory (optional if only class-specific folders are needed)\n",
    "        #     shutil.copy(image_path, general_dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedGroup K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Number of training samples: 13305\n",
      "Number of validation samples: 3183\n",
      "Total samples: 16488\n",
      "Actual train ratio: 0.81 (should be 0.8)\n",
      "Actual validation ratio: 0.19 (should be 0.2)\n",
      "Mean difference: 1.0099\n",
      "\n",
      "Species percentages by split:\n",
      "\n",
      "                  train  val\n",
      "antelope_duiker      14   15\n",
      "bird                  9   10\n",
      "blank                13   13\n",
      "civet_genet          15   11\n",
      "hog                   5    6\n",
      "leopard              13   14\n",
      "monkey_prosimian     15   15\n",
      "rodent               12   12\n",
      "Iteration 2\n",
      "Number of training samples: 13350\n",
      "Number of validation samples: 3138\n",
      "Total samples: 16488\n",
      "Actual train ratio: 0.81 (should be 0.8)\n",
      "Actual validation ratio: 0.19 (should be 0.2)\n",
      "Mean difference: 1.3790\n",
      "\n",
      "Species percentages by split:\n",
      "\n",
      "                  train  val\n",
      "antelope_duiker      14   15\n",
      "bird                  9   10\n",
      "blank                13   14\n",
      "civet_genet          15   10\n",
      "hog                   5    6\n",
      "leopard              13   14\n",
      "monkey_prosimian     14   15\n",
      "rodent               12   12\n",
      "Iteration 3\n",
      "Number of training samples: 13334\n",
      "Number of validation samples: 3154\n",
      "Total samples: 16488\n",
      "Actual train ratio: 0.81 (should be 0.8)\n",
      "Actual validation ratio: 0.19 (should be 0.2)\n",
      "Mean difference: 1.2889\n",
      "\n",
      "Species percentages by split:\n",
      "\n",
      "                  train  val\n",
      "antelope_duiker      14   15\n",
      "bird                  9   10\n",
      "blank                13   14\n",
      "civet_genet          15   10\n",
      "hog                   5    6\n",
      "leopard              13   14\n",
      "monkey_prosimian     14   15\n",
      "rodent               11   13\n",
      "Iteration 4\n",
      "Number of training samples: 12614\n",
      "Number of validation samples: 3874\n",
      "Total samples: 16488\n",
      "Actual train ratio: 0.77 (should be 0.8)\n",
      "Actual validation ratio: 0.23 (should be 0.2)\n",
      "Mean difference: 4.2488\n",
      "\n",
      "Species percentages by split:\n",
      "\n",
      "                  train  val\n",
      "antelope_duiker      15   12\n",
      "bird                 10    8\n",
      "blank                14   11\n",
      "civet_genet          10   27\n",
      "hog                   6    5\n",
      "leopard              14   11\n",
      "monkey_prosimian     15   12\n",
      "rodent               12   10\n",
      "Iteration 5\n",
      "Number of training samples: 13349\n",
      "Number of validation samples: 3139\n",
      "Total samples: 16488\n",
      "Actual train ratio: 0.81 (should be 0.8)\n",
      "Actual validation ratio: 0.19 (should be 0.2)\n",
      "Mean difference: 1.2620\n",
      "\n",
      "Species percentages by split:\n",
      "\n",
      "                  train  val\n",
      "antelope_duiker      14   15\n",
      "bird                  9   10\n",
      "blank                13   14\n",
      "civet_genet          15   10\n",
      "hog                   5    6\n",
      "leopard              13   14\n",
      "monkey_prosimian     14   15\n",
      "rodent               12   12\n",
      "The best iteration is iteration 1 with a mean difference of 1.0099\n"
     ]
    }
   ],
   "source": [
    "# Sampling a fraction of the data for stratification and setting up the file paths for the corresponding labels\n",
    "frac = 1\n",
    "y = train_labels.sample(frac=frac, random_state=42)\n",
    "x = train_features.loc[y.index].filepath.to_frame()\n",
    "\n",
    "# Preparing lists of necessary features for StratifiedGroupKFold: site, sample IDs, and class labels\n",
    "list_of_sites = train_features.loc[y.index]['site'].tolist()\n",
    "list_of_ids = train_features.loc[y.index].index.tolist()\n",
    "list_of_class_numbers = y.idxmax(axis=1).astype('category').cat.codes.tolist()\n",
    "\n",
    "# Define the test set proportion and calculate the number of folds for StratifiedGroupKFold\n",
    "test_size = 0.2\n",
    "n_splits = int(1 / test_size)\n",
    "\n",
    "# Initialize StratifiedGroupKFold for creating splits based on stratification criteria\n",
    "sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "# Generate stratified train/validation splits\n",
    "iteration_splits = list(sgkf.split(list_of_ids, list_of_class_numbers, list_of_sites))\n",
    "\n",
    "# Create a dictionary to store train/validation data for each fold\n",
    "fold_data = {f\"fold_{i+1}\": {\"x_train\": [], \"y_train\": [], \"x_val\": [], \"y_val\": []} for i in range(n_splits)}\n",
    "\n",
    "# Iterate through the splits, process each fold, and store results for later evaluation\n",
    "fold_results = []\n",
    "for iteration, (train_idx, val_idx) in enumerate(iteration_splits, start=1):\n",
    "    # Extracting train and validation IDs for the current fold\n",
    "    train_ids = [list_of_ids[i] for i in train_idx]\n",
    "    val_ids = [list_of_ids[i] for i in val_idx]\n",
    "\n",
    "    # Prepare train and validation datasets based on the current split\n",
    "    x_train = train_features.loc[train_ids]\n",
    "    y_train = train_labels.loc[train_ids]\n",
    "    x_val = train_features.loc[val_ids]\n",
    "    y_val = train_labels.loc[val_ids]\n",
    "\n",
    "    # Storing the split data for later access\n",
    "    fold_data[f\"fold_{iteration}\"][\"x_train\"] = x_train\n",
    "    fold_data[f\"fold_{iteration}\"][\"y_train\"] = y_train\n",
    "    fold_data[f\"fold_{iteration}\"][\"x_val\"] = x_val\n",
    "    fold_data[f\"fold_{iteration}\"][\"y_val\"] = y_val\n",
    "\n",
    "    # Evaluate class distribution for both train and validation sets\n",
    "    train_distribution = y_train.sum()\n",
    "    val_distribution = y_val.sum()\n",
    "\n",
    "    # Compute the percentage representation of each class in train and validation datasets\n",
    "    train_proportion = train_distribution / len(y_train) * 100\n",
    "    val_proportion = val_distribution / len(y_val) * 100\n",
    "\n",
    "    fold_results.append((train_proportion, val_proportion))\n",
    "\n",
    "    # Calculate the mean difference in class distribution between train and validation\n",
    "    differences = np.abs(train_proportion - val_proportion)\n",
    "    mean_difference = differences.mean()\n",
    "\n",
    "    # Debug: Validate the sample count and proportions in the split\n",
    "    num_train = len(x_train)\n",
    "    num_val = len(x_val)\n",
    "    total = num_train + num_val\n",
    "    actual_train_ratio = num_train / total\n",
    "    actual_val_ratio = num_val / total\n",
    "\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    print(f\"Number of training samples: {num_train}\")\n",
    "    print(f\"Number of validation samples: {num_val}\")\n",
    "    print(f\"Total samples: {total}\")\n",
    "    print(f\"Actual train ratio: {actual_train_ratio:.2f} (should be {1 - test_size})\")\n",
    "    print(f\"Actual validation ratio: {actual_val_ratio:.2f} (should be {test_size})\")\n",
    "    print(f\"Mean difference: {mean_difference:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Display the class distribution percentages for both train and validation sets\n",
    "    split_pcts = pd.DataFrame(\n",
    "        {\n",
    "            \"train\": y_train.idxmax(axis=1).value_counts(normalize=True),\n",
    "            \"val\": y_val.idxmax(axis=1).value_counts(normalize=True),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Species percentages by split:\\n\")\n",
    "    print((split_pcts.fillna(0) * 100).astype(int))\n",
    "\n",
    "    # Calculate and score the split based on class distribution variance\n",
    "    train_std = split_pcts['train'].std()\n",
    "    val_std = split_pcts['val'].std()\n",
    "    score = train_std + val_std\n",
    "\n",
    "# Post-process: Calculate mean differences for all splits and select the best one based on minimal difference\n",
    "mean_differences = []\n",
    "for iteration, (train_proportion, val_proportion) in enumerate(fold_results, start=1):\n",
    "    differences = np.abs(train_proportion - val_proportion)\n",
    "    mean_difference = differences.mean()\n",
    "    mean_differences.append(mean_difference)\n",
    "\n",
    "best_iteration_index = np.argmin(mean_differences)\n",
    "print(f\"The best iteration is iteration {best_iteration_index + 1} with a mean difference of {mean_differences[best_iteration_index]:.4f}\")\n",
    "\n",
    "# Select the best iteration and retrieve the corresponding train/validation datasets\n",
    "best_iteration_key = f\"fold_{best_iteration_index + 1}\"\n",
    "x_train = fold_data[best_iteration_key][\"x_train\"]\n",
    "y_train = fold_data[best_iteration_key][\"y_train\"]\n",
    "x_val = fold_data[best_iteration_key][\"x_val\"]\n",
    "y_val = fold_data[best_iteration_key][\"y_val\"]\n",
    "\n",
    "# Clear any previously stored train and validation data from directories\n",
    "clear_directory(os.path.join(dataset_path, 'train'))\n",
    "clear_directory(os.path.join(dataset_path, 'validation'))\n",
    "\n",
    "# Copy the new train/validation data into the appropriate directories for model training\n",
    "copy_images(x_train, y_train, os.path.join(dataset_path, 'train'))\n",
    "copy_images(x_val, y_val, os.path.join(dataset_path, 'validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check for overlap of locations between training and validation sets and lack of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique sites in the training set: 120\n",
      "Number of unique sites in the validation set: 28\n",
      "Total number of unique sites in the dataset: 148\n",
      "\n",
      "No overlap between training and validation sets.\n",
      "\n",
      "No sites are missing from both training and validation sets.\n"
     ]
    }
   ],
   "source": [
    "def check_site_overlap_and_missing_sites(x_train, x_val, train_features):\n",
    "\n",
    "    # Print the sites for debugging purposes\n",
    "    # print(\"Train sites:\\n\", train_sites.value_counts())\n",
    "    # print(\"\\nValidation sites:\\n\", val_sites.value_counts())\n",
    "\n",
    "    # Extract the 'site' column from the train and validation sets\n",
    "    train_sites = train_features.loc[x_train.index]['site']\n",
    "    val_sites = train_features.loc[x_val.index]['site']\n",
    "\n",
    "    # Count the unique sites in training and validation sets\n",
    "    unique_train_sites = set(train_sites)\n",
    "    unique_val_sites = set(val_sites)\n",
    "\n",
    "    # Set of all unique sites in the dataset\n",
    "    all_sites = set(train_features['site'])\n",
    "\n",
    "    # Identify common sites between training and validation sets\n",
    "    common_sites = unique_train_sites.intersection(unique_val_sites)\n",
    "\n",
    "    # Find sites missing from both training and validation sets\n",
    "    missing_sites = all_sites - (unique_train_sites.union(unique_val_sites))\n",
    "\n",
    "    # Output the number of unique sites in each set\n",
    "    print(\"Number of unique sites in the training set:\", len(unique_train_sites))\n",
    "    print(\"Number of unique sites in the validation set:\", len(unique_val_sites))\n",
    "    print(\"Total number of unique sites in the dataset:\", len(all_sites))\n",
    "\n",
    "    # If there are common sites, display them\n",
    "    if common_sites:\n",
    "        print(\"\\nOverlap between training and validation sets:\")\n",
    "        for site in common_sites:\n",
    "            print(f\"Site {site} appears in both the training and validation sets.\")\n",
    "    else:\n",
    "        print(\"\\nNo overlap between training and validation sets.\")\n",
    "\n",
    "    # If there are missing sites, display them\n",
    "    if missing_sites:\n",
    "        print(\"\\nSites that are missing from both training and validation sets:\")\n",
    "        for site in missing_sites:\n",
    "            print(f\"Site {site} is missing from both the training and validation sets.\")\n",
    "    else:\n",
    "        print(\"\\nNo sites are missing from both training and validation sets.\")\n",
    "\n",
    "# Example usage of the function\n",
    "check_site_overlap_and_missing_sites(x_train, x_val, train_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what `x_train` and `y_train` look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZJ008416</th>\n",
       "      <td>train_features/ZJ008416.jpg</td>\n",
       "      <td>S0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009568</th>\n",
       "      <td>train_features/ZJ009568.jpg</td>\n",
       "      <td>S0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ012401</th>\n",
       "      <td>train_features/ZJ012401.jpg</td>\n",
       "      <td>S0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ008603</th>\n",
       "      <td>train_features/ZJ008603.jpg</td>\n",
       "      <td>S0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009236</th>\n",
       "      <td>train_features/ZJ009236.jpg</td>\n",
       "      <td>S0002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filepath   site\n",
       "id                                          \n",
       "ZJ008416  train_features/ZJ008416.jpg  S0036\n",
       "ZJ009568  train_features/ZJ009568.jpg  S0088\n",
       "ZJ012401  train_features/ZJ012401.jpg  S0198\n",
       "ZJ008603  train_features/ZJ008603.jpg  S0031\n",
       "ZJ009236  train_features/ZJ009236.jpg  S0002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZJ008416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ012401</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ008603</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJ009236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          antelope_duiker  bird  blank  civet_genet  hog  leopard  \\\n",
       "id                                                                  \n",
       "ZJ008416              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ009568              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ012401              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ008603              1.0   0.0    0.0          0.0  0.0      0.0   \n",
       "ZJ009236              0.0   0.0    0.0          0.0  0.0      0.0   \n",
       "\n",
       "          monkey_prosimian  rodent  \n",
       "id                                  \n",
       "ZJ008416               0.0     1.0  \n",
       "ZJ009568               0.0     1.0  \n",
       "ZJ012401               1.0     0.0  \n",
       "ZJ008603               0.0     0.0  \n",
       "ZJ009236               1.0     0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13305, 2), (13305, 8), (3183, 2), (3183, 8))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's validate that our split has resulted in roughly similar relative distributions of species across the train and val sets (because of how we passed `stratify=y` above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species percentages by split:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antelope_duiker</th>\n",
       "      <td>14.84</td>\n",
       "      <td>15.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>9.87</td>\n",
       "      <td>10.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blank</th>\n",
       "      <td>13.30</td>\n",
       "      <td>13.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civet_genet</th>\n",
       "      <td>15.48</td>\n",
       "      <td>11.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hog</th>\n",
       "      <td>5.89</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leopard</th>\n",
       "      <td>13.54</td>\n",
       "      <td>14.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <td>15.00</td>\n",
       "      <td>15.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rodent</th>\n",
       "      <td>12.08</td>\n",
       "      <td>12.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train    val\n",
       "antelope_duiker   14.84  15.71\n",
       "bird               9.87  10.30\n",
       "blank             13.30  13.92\n",
       "civet_genet       15.48  11.44\n",
       "hog                5.89   6.09\n",
       "leopard           13.54  14.20\n",
       "monkey_prosimian  15.00  15.58\n",
       "rodent            12.08  12.76"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_pcts = pd.DataFrame(\n",
    "    {\n",
    "        \"train\": y_train.idxmax(axis=1).value_counts(normalize=True),\n",
    "        \"val\": y_val.idxmax(axis=1).value_counts(normalize=True),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Species percentages by split:\")\n",
    "(split_pcts.fillna(0) * 100).astype(int)\n",
    "(split_pcts.fillna(0) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>number of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw\\train\\antelope_duiker</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw\\train\\bird</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw\\train\\blank</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/raw\\train\\civet_genet</td>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/raw\\train\\hog</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/raw\\train\\leopard</td>\n",
       "      <td>1802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/raw\\train\\monkey_prosimian</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/raw\\train\\rodent</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             train  number of images\n",
       "0   data/raw\\train\\antelope_duiker              1974\n",
       "1              data/raw\\train\\bird              1313\n",
       "2             data/raw\\train\\blank              1770\n",
       "3       data/raw\\train\\civet_genet              2059\n",
       "4               data/raw\\train\\hog               784\n",
       "5           data/raw\\train\\leopard              1802\n",
       "6  data/raw\\train\\monkey_prosimian              1996\n",
       "7            data/raw\\train\\rodent              1607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "      <th>number of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw\\validation\\antelope_duiker</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw\\validation\\bird</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw\\validation\\blank</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/raw\\validation\\civet_genet</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/raw\\validation\\hog</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/raw\\validation\\leopard</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/raw\\validation\\monkey_prosimian</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/raw\\validation\\rodent</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             validation  number of images\n",
       "0   data/raw\\validation\\antelope_duiker               500\n",
       "1              data/raw\\validation\\bird               328\n",
       "2             data/raw\\validation\\blank               443\n",
       "3       data/raw\\validation\\civet_genet               364\n",
       "4               data/raw\\validation\\hog               194\n",
       "5           data/raw\\validation\\leopard               452\n",
       "6  data/raw\\validation\\monkey_prosimian               496\n",
       "7            data/raw\\validation\\rodent               406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_features</th>\n",
       "      <th>number of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw\\test_features</td>\n",
       "      <td>4464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test_features  number of images\n",
       "0  data/raw\\test_features              4464"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define dictionaries to hold data for each category\n",
    "data_train = []\n",
    "data_validation = []\n",
    "data_test_features = []\n",
    "\n",
    "# Iterate over each subdirectory\n",
    "for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
    "    # Count number of images in the current directory\n",
    "    num_images = sum(1 for filename in filenames if filename.lower().endswith('.jpg'))\n",
    "    if num_images > 0:\n",
    "        # Check the category of the current directory based on the path\n",
    "        parts = dirpath.split(os.sep)\n",
    "        if \"train\" in parts:\n",
    "            data_train.append({'train': dirpath, 'number of images': num_images})\n",
    "        elif \"validation\" in parts:\n",
    "            data_validation.append({'validation': dirpath, 'number of images': num_images})\n",
    "        elif \"test_features\" in parts:\n",
    "            data_test_features.append({'test_features': dirpath, 'number of images': num_images})\n",
    "\n",
    "# Create DataFrames for each category with the specified column names\n",
    "df_train = pd.DataFrame(data_train)\n",
    "df_validation = pd.DataFrame(data_validation)\n",
    "df_test_features = pd.DataFrame(data_test_features)\n",
    "\n",
    "# Display each sorted DataFrame\n",
    "display(df_train)\n",
    "display(df_validation)\n",
    "display(df_test_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final file structure after split images look like this:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── train_features/\n",
    "│   ├── ZJ000001.jpg\n",
    "│   └── ...\n",
    "│\n",
    "├── test_features/\n",
    "│   ├── ZJ16488.jpg\n",
    "│   └── ...\n",
    "│\n",
    "├── train/\n",
    "│   ├── antelope_duiker (class 1)/\n",
    "│   │   ├── ZJ000001.jpg\n",
    "│   │   └── ...\n",
    "│   ├── ...\n",
    "│   └── hog (class 8)/\n",
    "│       ├── ZJ000008.jpg\n",
    "│       └── ...\n",
    "│\n",
    "└── validation/\n",
    "    ├── antelope_duiker (class 1)/\n",
    "    │   ├── ZJ000009.jpg\n",
    "    │   └── ...\n",
    "    ├── ...\n",
    "    └── hog (class 8)/\n",
    "        ├── ZJ000016.jpg\n",
    "        └── ...\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
