{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GFE_XiDcepj"
   },
   "source": [
    "# Introduction to image classification using camera trap images\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up environment\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import some necessary libraries of the usual suspects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science libraries\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# Visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Tensorflow and Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "# # CLI and Python library for interacting with the Weights and Biases API\n",
    "# import wandb\n",
    "# from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\GitHub\\CameraTrap-Animal-Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow was built with CUDA (GPU) support:\", tf.test.is_built_with_cuda())\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Python version:\", platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = r'C:\\GitHub\\CameraTrap-Animal-Classification\\data\\raw'\n",
    "dataset_path = 'data/raw'\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "train_features = pd.read_csv(os.path.join(dataset_path, 'train_features.csv'), index_col=\"id\")\n",
    "test_features = pd.read_csv(os.path.join(dataset_path, 'test_features.csv'), index_col=\"id\")\n",
    "train_labels = pd.read_csv(os.path.join(dataset_path, 'train_labels.csv'), index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arJuVxM1ji5O"
   },
   "source": [
    "## 2. Build the model\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFQ5MSUCjl3R"
   },
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729791117489,
     "user": {
      "displayName": "Daniel Sędłak",
      "userId": "12654360482244446046"
     },
     "user_tz": -120
    },
    "id": "XM_evjhvjmcS"
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 360 # 224\n",
    "IMG_WIDTH = 640 # 224\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "BASE_LEARNING_RATE = 1e-3\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log a run to start tracking system metrics and console logs in Weights&Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login(key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(\n",
    "#     project=\"Conservision_Practice_Area_Image_Classification\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.config.update({\n",
    "#     \"IMG_HEIGHT\": IMG_HEIGHT,\n",
    "#     \"IMG_WIDTH\": IMG_WIDTH,\n",
    "#     \"IMG_SIZE\": IMG_SIZE,\n",
    "#     \"CHANNELS\": CHANNELS,\n",
    "#     \"BATCH_SIZE\": BATCH_SIZE,\n",
    "#     \"EPOCHS\": EPOCHS,\n",
    "#     \"BASE_LEARNING_RATE\": BASE_LEARNING_RATE,\n",
    "#     \"NUM_CLASSES\": NUM_CLASSES\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERgzrlAQojye"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet import preprocess_input\n",
    "# from keras.applications.efficientnet import preprocess_input\n",
    "# from keras.applications.convnext import preprocess_input\n",
    "\n",
    "dataset_path = r'data/raw'\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "species_labels = sorted(train_labels.columns.unique())\n",
    "train_dir = os.path.join(dataset_path, 'train')\n",
    "valid_dir = os.path.join(dataset_path, 'validation')\n",
    "\n",
    "func_preprocess_input = preprocess_input\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=func_preprocess_input,\n",
    "    # horizontal_flip=True,\n",
    "    # rotation_range=5,\n",
    "    # shear_range=0.1,\n",
    "    # zoom_range=[0.9, 1.0],\n",
    "    # brightness_range=[0.9, 1.1],\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "valid_ds = validation_datagen.flow_from_directory(\n",
    "    directory=valid_dir,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729791132195,
     "user": {
      "displayName": "Daniel Sędłak",
      "userId": "12654360482244446046"
     },
     "user_tz": -120
    },
    "id": "SGGoVXMEn4mK",
    "outputId": "ef0b5843-fd94-4f89-d9c6-f95ae5814bc4"
   },
   "outputs": [],
   "source": [
    "# Inspect a batch from train_ds\n",
    "images, labels = next(iter(train_ds))\n",
    "print(\"Train images shape and type:\", images.dtype, images.shape)\n",
    "print(\"Train labels shape and type:\", labels.dtype, labels.shape)\n",
    "\n",
    "# Inspect a batch from val_dataset\n",
    "images, labels = next(iter(valid_ds))\n",
    "print(\"Validation images shape and type:\", images.dtype, images.shape)\n",
    "print(\"Validation labels shape and type:\", labels.dtype, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization augmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 'ZJ004793' # 'ZJ000048'\n",
    "\n",
    "train_features = pd.read_csv(os.path.join(dataset_path, 'train_features.csv'), index_col=\"id\")\n",
    "\n",
    "image_filepath = train_features.loc[image_id, 'filepath']\n",
    "image_fullpath = os.path.join(dataset_path, image_filepath)\n",
    "\n",
    "original_image = Image.open(image_fullpath)\n",
    "original_image_np = np.array(original_image)\n",
    "\n",
    "augmenters = {\n",
    "    \"Horizontal Flip\": ImageDataGenerator(horizontal_flip=True),\n",
    "    \"Rotation\": ImageDataGenerator(rotation_range=5),\n",
    "    \"Shear\": ImageDataGenerator(shear_range=0.1),\n",
    "    \"Zoom\": ImageDataGenerator(zoom_range=[0.9, 1.0]),\n",
    "    \"Brightness\": ImageDataGenerator(brightness_range=[0.9, 1.1]),\n",
    "    # \"Fill Mode\": ImageDataGenerator(fill_mode='nearest')\n",
    "}\n",
    "\n",
    "augmenters_names = {\n",
    "    \"Horizontal Flip\": \"Example 2: horizontal_flip\",\n",
    "    \"Rotation\": \"Example 3: rotation_range\",\n",
    "    \"Shear\": \"Example 4: shear_range\",\n",
    "    \"Zoom\": \"Example 5: zoom_range\",\n",
    "    \"Brightness\": \"Example 6: brightness_range\",\n",
    "    # \"Fill Mode\": \"Example 7: fill_mode\"\n",
    "}\n",
    "\n",
    "# Function to augment image with optional seed for reproducibility\n",
    "def augments_image(image, datagen, seed=None):\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    iterator = datagen.flow(image, batch_size=1, seed=seed)  # Use seed if provided\n",
    "    augmented_image = iterator.next()[0].astype('uint8')\n",
    "    return augmented_image\n",
    "\n",
    "# Number of augmentations\n",
    "num_augmentations = len(augmenters)\n",
    "num_columns = 2\n",
    "num_rows = (num_augmentations + 1 + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, num_rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display original image\n",
    "axes[0].imshow(original_image_np)\n",
    "axes[0].set_title(\"Example 1: original\")\n",
    "axes[0].axis('on')\n",
    "\n",
    "# Decide if you want reproducibility\n",
    "use_seed = True  # Set to False if you don't want consistent results\n",
    "seed_value = 34  # Seed value to use if reproducibility is desired\n",
    "\n",
    "# Display augmented images\n",
    "for ax, (aug_name, datagen) in zip(axes[1:], augmenters.items()):  # Start from the second subplot\n",
    "    augmented_image_np = augments_image(original_image_np, datagen, seed_value if use_seed else None)\n",
    "    ax.imshow(augmented_image_np)\n",
    "    ax.set_title(augmenters_names[aug_name])\n",
    "    ax.axis('on')\n",
    "\n",
    "# Hide unused axes\n",
    "for ax in axes[num_augmentations + 1:]:\n",
    "    ax.axis('on')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZMI4rhyogaC"
   },
   "source": [
    "### Define pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet101, EfficientNetB0, EfficientNetB6, ConvNeXtSmall, ConvNeXtBase\n",
    "\n",
    "# choose base network\n",
    "network = 'ResNet101'\n",
    "\n",
    "shape = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "\n",
    "if network == 'ResNet101':\n",
    "    pretrained_model = ResNet101(include_top=False, weights='imagenet', input_shape=shape)\n",
    "elif network == 'EfficientNetB0':\n",
    "    pretrained_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=shape)\n",
    "elif network == 'EfficientNetB6':\n",
    "    pretrained_model = EfficientNetB6(include_top=False, weights='imagenet', input_shape=shape)\n",
    "elif network == 'ConvNeXtSmall':\n",
    "    pretrained_model = ConvNeXtSmall(include_top=False, weights='imagenet', input_shape=shape)\n",
    "elif network == 'ConvNeXtBase':\n",
    "    pretrained_model = ConvNeXtBase(include_top=False, weights='imagenet', input_shape=shape)\n",
    "else:\n",
    "    print('Network name does not exist')\n",
    "\n",
    "pretrained_model.trainable = False # default is True\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(pretrained_model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# for layer in pretrained_model.layers[331:]:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1729791136295,
     "user": {
      "displayName": "Daniel Sędłak",
      "userId": "12654360482244446046"
     },
     "user_tz": -120
    },
    "id": "JekUtk1po8k5"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "\n",
    "    pretrained_model,\n",
    "\n",
    "    # Flatten the output of the pretrained model\n",
    "    GlobalAveragePooling2D(),\n",
    "\n",
    "    # Add custom layers on top of the pretrained model\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(rate=0.1),\n",
    "    \n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(rate=0.1),\n",
    "    \n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(rate=0.1),\n",
    "    \n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dropout(rate=0.1),\n",
    "    \n",
    "    Dense(units=NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729791136295,
     "user": {
      "displayName": "Daniel Sędłak",
      "userId": "12654360482244446046"
     },
     "user_tz": -120
    },
    "id": "-YrtvyKvvBuA",
    "outputId": "2a98d113-c2b2-4076-f8cd-f37807679004"
   },
   "outputs": [],
   "source": [
    "# pretrained_model.trainable = False\n",
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuzHQXkTqI89"
   },
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729791136295,
     "user": {
      "displayName": "Daniel Sędłak",
      "userId": "12654360482244446046"
     },
     "user_tz": -120
    },
    "id": "D-3zLJUpvFAt"
   },
   "outputs": [],
   "source": [
    "model_name = pretrained_model.name\n",
    "timestamp = datetime.datetime.now().strftime(\"%H%M-%d%m%Y\")\n",
    "\n",
    "checkpoint_loss = ModelCheckpoint(filepath=(f'model_best_loss_{model_name}_{timestamp}.keras'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False)\n",
    "\n",
    "checkpoint_acc = ModelCheckpoint(filepath=(f'model_best_acc_{model_name}_{timestamp}.keras'),\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False)\n",
    "\n",
    "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                               factor=0.1,\n",
    "#                               patience=3,\n",
    "#                               verbose=1,\n",
    "#                               min_lr=1e-6)\n",
    "\n",
    "# early_stopping = EarlyStopping(\n",
    "#     min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "#     patience=5, # how many epochs to wait before stopping\n",
    "#     restore_best_weights=True,\n",
    "# )\n",
    "\n",
    "# wandb_logger = WandbMetricsLogger(log_freq=1)\n",
    "\n",
    "# callbacks = [checkpoint_loss, checkpoint_acc, wandb_logger]\n",
    "callbacks = [checkpoint_loss, checkpoint_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=BASE_LEARNING_RATE),\n",
    "              loss=CategoricalCrossentropy(name=\"categorical_crossentropy\"),\n",
    "              metrics=CategoricalAccuracy(name=\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 15487,
     "status": "error",
     "timestamp": 1729791151776,
     "user": {
      "displayName": "Daniel Sędłak",
      "userId": "12654360482244446046"
     },
     "user_tz": -120
    },
    "id": "o4gsIL39vJY9",
    "outputId": "b415ab68-6de3-4923-b9df-8c53d9bfc81d"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_ds,\n",
    "                    max_queue_size=12,\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Close the W&B run\n",
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-_uaSCSNrH2"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmdtDZvvcUoR"
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history_dict)\n",
    "new_index = []\n",
    "# Generate the new index labels using a for loop\n",
    "for i in range(1, len(history_df) + 1):\n",
    "    new_index.append('Epoch ' + str(i))\n",
    "history_df.index = new_index\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coa5v_EKcUoR"
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# Extract values from the training history\n",
    "history_dict = history.history\n",
    "training_loss = history_dict['loss']\n",
    "validation_loss = history_dict['val_loss']\n",
    "training_accuracy = history_dict['accuracy']\n",
    "validation_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "def training_plot(metrics, history):\n",
    "    num_epochs = len(history.history[metrics[0]])  # Number of epochs\n",
    "    epochs = range(1, num_epochs + 1)  # Create a range object for the x-axis values\n",
    "\n",
    "    f, ax = plt.subplots(2, len(metrics)//2, figsize=(5 * len(metrics), 12))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        training_metric = history.history[metric]\n",
    "        validation_metric = history.history['val_' + metric]\n",
    "\n",
    "        ax[idx].plot(epochs, training_metric, ls='-', marker='o', color='red', label='train_' + metric)\n",
    "        ax[idx].plot(epochs, validation_metric, ls='--', marker='o', color='blue', label='val_' + metric)\n",
    "\n",
    "        ax[idx].set_xlabel(\"epoka\")\n",
    "        ax[idx].set_ylabel(metric)\n",
    "        ax[idx].legend()\n",
    "        ax[idx].grid()\n",
    "        ax[idx].set_title(f'{metric.capitalize()} - trening i walidacja')\n",
    "        ax[idx].set_xticks(epochs)  # Set the x-ticks to match the epochs\n",
    "        ax[idx].set_xlim([0.6, num_epochs + 0.4])  # Adding a margin to the left and right of the plot\n",
    "        # ax[idx].yaxis.set_major_locator(MultipleLocator(0.05)) # Set y-axis ticks to have intervals of 0.1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "training_plot(['loss', 'accuracy'], history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehlQd4JFcUoR"
   },
   "source": [
    "### Save model and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jsV-A62cUoR"
   },
   "outputs": [],
   "source": [
    "def generate_model_name(base_name, model_name, epoch=None, val_loss=None, val_accuracy=None):\n",
    "    name_parts = [base_name,\n",
    "                  model_name,\n",
    "                  f\"epoch_{epoch}\" if epoch is not None else \"\",\n",
    "                  f\"val_loss_{val_loss:.4f}\" if val_loss is not None else \"\",\n",
    "                  f\"val_acc_{val_accuracy:.4f}\" if val_accuracy is not None else \"\"]\n",
    "\n",
    "    return \"_\".join([part for part in name_parts if part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RRFZ_9jcUoS"
   },
   "outputs": [],
   "source": [
    "best_val_loss_idx = history.history['val_loss'].index(min(history.history['val_loss']))\n",
    "# best_val_acc_idx = history.history['val_acc'].index(min(history.history['val_acc']))\n",
    "best_val_loss = history.history['val_loss'][best_val_loss_idx]\n",
    "best_val_acc = history.history['val_accuracy'][best_val_loss_idx]\n",
    "\n",
    "# Save training history\n",
    "history_model_df = pd.DataFrame(history_dict)\n",
    "history_file_name = generate_model_name(base_name='history_best_loss',\n",
    "                                        model_name=model_name,\n",
    "                                        epoch=best_val_loss_idx + 1,\n",
    "                                        val_loss=best_val_loss,\n",
    "                                        val_accuracy=best_val_acc) + '.csv'\n",
    "\n",
    "history_model_df.to_csv(history_file_name, index=False)\n",
    "\n",
    "final_model_name = generate_model_name(\n",
    "    base_name='model_saved',\n",
    "    model_name=model_name,\n",
    "    epoch=None,\n",
    "    val_loss=None,\n",
    "    val_accuracy=None)\n",
    "\n",
    "model.save(f\"{final_model_name}.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwR3PR28cUoS"
   },
   "source": [
    "### Load history and model (plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W093scZncUoT"
   },
   "outputs": [],
   "source": [
    "# Path to the CSV file\n",
    "history_path = os.path.join(\"modele_wyniki\\ResNet-101\\Model2(StratifiedGroupKFold)\\history_best_loss_resnet101_epoch_1_val_loss_1.6934_val_acc_0.3827.csv\")\n",
    "history_load = pd.read_csv(history_path)\n",
    "\n",
    "# Adding a column 'epoch' with values 'Epoch 1', 'Epoch 2', etc.\n",
    "history_load.insert(0, 'epoch', ['Epoch ' + str(i) for i in range(1, len(history_load) + 1)])\n",
    "\n",
    "# Changing the indexing to start from 1\n",
    "history_load.index = range(1, len(history_load) + 1)\n",
    "history_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKrIGQ7pcUoT"
   },
   "outputs": [],
   "source": [
    "from custom_layers_ConvNeXt import LayerScale, StochasticDepth\n",
    "\n",
    "model_path = os.path.join(\"modele_wyniki\\ResNet-101\\Model2(StratifiedGroupKFold)\\model_best_loss_resnet101_1802-23082024.keras\")\n",
    "\n",
    "load_model = tf.keras.models.load_model(model_path)\n",
    "# load_model = tf.keras.models.load_model(model_path, custom_objects={'LayerScale': LayerScale, 'StochasticDepth': StochasticDepth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hC4qQpXzcUoT"
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def training_plot(metrics, history_df, fontsize=18):\n",
    "    num_epochs = len(history_df)  # Number of epochs\n",
    "    epochs = range(1, num_epochs + 1)  # Create a range object for the x-axis values, starting from 1\n",
    "    tick_intervals = range(0, num_epochs + 1, 2)  # Set tick intervals at 0, 2, 4, etc.\n",
    "\n",
    "    f, ax = plt.subplots(1, len(metrics), figsize=(8 * len(metrics), 7))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        training_metric = history_df[metric]\n",
    "        validation_metric = history_df['val_' + metric]\n",
    "\n",
    "        # Use markers for training and validation metrics\n",
    "        ax[idx].plot(epochs, training_metric, ls='-', marker='o', color='red', label='train_' + metric) # red\n",
    "        ax[idx].plot(epochs, validation_metric, ls='--', marker='o', color='blue', label='validation_' + metric) # blue\n",
    "\n",
    "        # Set labels and title with specified font size\n",
    "        ax[idx].set_xlabel(\"epoka\", fontsize=fontsize)\n",
    "        ax[idx].set_ylabel('wartość ' + metric, fontsize=fontsize)\n",
    "        ax[idx].legend(fontsize=fontsize)\n",
    "        ax[idx].grid()\n",
    "        ax[idx].set_title(f'{metric.capitalize()} - trening i walidacja', fontsize=fontsize+2)\n",
    "        ax[idx].set_xticks(tick_intervals)  # Set the x-ticks to every 2 epochs starting from 0\n",
    "        ax[idx].set_xlim([0, num_epochs + 0.4])  # Set x-axis limits to include 0\n",
    "\n",
    "        # ax[idx].yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "        # Adjust the tick label size\n",
    "        ax[idx].tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "training_plot(['loss', 'accuracy'], history_load, fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ud1W90AEcUoU"
   },
   "source": [
    "## 4. Evaluation on validation set\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWlMwfwocUoU"
   },
   "source": [
    "### Make predictions labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yewVo-dHcUoU"
   },
   "outputs": [],
   "source": [
    "validation_loss, validation_accuracy = load_model.evaluate(valid_ds, max_queue_size=14, workers=4)\n",
    "print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {validation_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSoZBPE5cUoU"
   },
   "outputs": [],
   "source": [
    "# predictions = load_model.predict(valid_ds, max_queue_size=14, workers=4)\n",
    "\n",
    "# val_preds_df = pd.DataFrame(predictions, columns=species_labels)\n",
    "# # Extract filenames without path and extension\n",
    "# image_ids = [os.path.splitext(os.path.basename(file_path))[0] for file_path in valid_ds.filenames]\n",
    "# val_preds_df.index = image_ids\n",
    "\n",
    "# val_preds_df = val_preds_df.round(6)\n",
    "# val_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWlj8VImcUoU"
   },
   "outputs": [],
   "source": [
    "# Generate predictions using the validation generator\n",
    "predictions = load_model.predict(valid_ds, max_queue_size=14, workers=4)\n",
    "# Create a DataFrame with the predictions\n",
    "val_preds_df = pd.DataFrame(predictions, columns=species_labels)\n",
    "# Extract the species labels (class names) from the generator\n",
    "species_labels = list(valid_ds.class_indices.keys())\n",
    "# Extract image IDs from the generator's filenames\n",
    "image_ids = [os.path.splitext(os.path.basename(file_path))[0] for file_path in valid_ds.filenames]\n",
    "val_preds_df.index = image_ids\n",
    "val_preds_df.index.name = None\n",
    "# Determine the predicted classes and their labels\n",
    "val_preds_df['predicted_label'] = val_preds_df.idxmax(axis=1)\n",
    "# Map the true class labels using the filenames directly\n",
    "val_preds_df['true_label'] = [os.path.basename(os.path.dirname(file_path)) for file_path in valid_ds.filenames]\n",
    "\n",
    "val_preds_df = val_preds_df.round(6)\n",
    "val_preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ5hJJ5UcUoV"
   },
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnqujn2-cUoV"
   },
   "outputs": [],
   "source": [
    "true_classes = valid_ds.classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "class_labels = list(valid_ds.class_indices.keys())\n",
    "\n",
    "report = classification_report(y_true=true_classes,\n",
    "                               y_pred=predicted_classes,\n",
    "                               target_names=class_labels,\n",
    "                               output_dict=True,\n",
    "                               zero_division=0)\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Jo8fwmBcUoV"
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0OkRFomcUoV"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=true_classes,\n",
    "    y_pred=predicted_classes,\n",
    "    display_labels=species_labels,\n",
    "    normalize=None,\n",
    "    ax=ax,\n",
    "    xticks_rotation=90,\n",
    "    colorbar=True,\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "ax.set_ylabel('Prawdziwe etykiety', fontsize=7, fontweight='bold')\n",
    "ax.set_xlabel('Prognozowane etykiety', fontsize=7, fontweight='bold')\n",
    "plt.title('Macierz pomyłek', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLyXwUJfcUoV"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=true_classes,\n",
    "    y_pred=predicted_classes,\n",
    "    display_labels=species_labels,\n",
    "    normalize='true',\n",
    "    ax=ax,\n",
    "    xticks_rotation=90,\n",
    "    colorbar=True,\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "ax.set_ylabel('Prawdziwe etykiety', fontsize=7, fontweight='bold')\n",
    "ax.set_xlabel('Prognozowane etykiety', fontsize=7, fontweight='bold')\n",
    "plt.title('Macierz pomyłek', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TuW7DKMcUoV"
   },
   "source": [
    "### Predicted labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_E5RQsYcUoV"
   },
   "outputs": [],
   "source": [
    "def load_data(dataset_path, subdir, features_df):\n",
    "    \"\"\"\n",
    "    Function loads data from a directory and creates DataFrames for features (x_data) and labels (y_data).\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_path: base path to the dataset directory\n",
    "    - subdir: subdirectory from which data should be loaded ('train' or 'validation')\n",
    "    - features_df: DataFrame containing additional features (e.g., 'site')\n",
    "\n",
    "    Returns:\n",
    "    - x_data: DataFrame containing file paths and features (site)\n",
    "    - y_data: DataFrame with one-hot encoded labels\n",
    "    \"\"\"\n",
    "    dir_path = os.path.join(dataset_path, subdir)\n",
    "\n",
    "    # Creating a list of dictionaries, where each dictionary contains file, site, and class information\n",
    "    data = [\n",
    "        {\n",
    "            'id': os.path.splitext(filename)[0],  # Extracting file ID without the extension\n",
    "            'filepath': os.path.join(subdir, filename),  # File path in the subdirectory\n",
    "            # Retrieving the 'site' value from the DataFrame based on the ID\n",
    "            'site': features_df.loc[os.path.splitext(filename)[0], 'site'] if os.path.splitext(filename)[0] in features_df.index else None,\n",
    "            'label': class_label  # Class name (e.g., 'antelope_duiker', 'bird')\n",
    "        }\n",
    "        for class_label in os.listdir(dir_path)  # Iterating through each class in the subdirectory\n",
    "        if os.path.isdir(os.path.join(dir_path, class_label))  # Checking if it is a directory (class)\n",
    "        for filename in os.listdir(os.path.join(dir_path, class_label))  # Iterating through each file in the given class\n",
    "    ]\n",
    "\n",
    "    # Creating a DataFrame from the list of dictionaries and setting 'id' as the index\n",
    "    data_df = pd.DataFrame(data).set_index('id')\n",
    "    # Separating 'filepath' and 'site' columns as x_data\n",
    "    x_data = data_df[['filepath', 'site']]\n",
    "    # Encoding labels with one-hot encoding (e.g., columns for each class) and converting to integers\n",
    "    y_data = pd.get_dummies(data_df['label']).astype(int)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_train, y_train = load_data(dataset_path, 'train', train_features)\n",
    "x_val, y_val = load_data(dataset_path, 'validation', train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q654CXoAcUoW"
   },
   "outputs": [],
   "source": [
    "# True labels distribution in the training set\n",
    "print(\"True labels (train):\")\n",
    "print(y_train.idxmax(axis=1).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNcDFi-OcUoW"
   },
   "outputs": [],
   "source": [
    "# Print the predicted labels distribution using idxmax on a copy with only numeric columns\n",
    "preds_only_df = val_preds_df[species_labels].copy()\n",
    "print(\"Predicted labels (validation):\")\n",
    "print(preds_only_df.idxmax(axis=1).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JABqYYSTcUoW"
   },
   "outputs": [],
   "source": [
    "# Print the true labels distribution in the validation set\n",
    "print(\"True labels (validation):\")\n",
    "print(y_val.idxmax(axis=1).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUkNA-1VcUoW"
   },
   "source": [
    "## 5. Submission test_features\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_EsN-MCcUoW"
   },
   "outputs": [],
   "source": [
    "test_features_dir = os.path.join(dataset_path, 'test_features')\n",
    "\n",
    "temp_test_dir = os.path.join(test_features_dir, 'temp_test_dir')\n",
    "os.makedirs(temp_test_dir, exist_ok=True)\n",
    "test_images_dir = os.path.join(temp_test_dir, 'test_images')\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(test_features_dir):\n",
    "    file_path = os.path.join(test_features_dir, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        shutil.copy(file_path, os.path.join(test_images_dir, file_name))\n",
    "\n",
    "func_preprocess_input = preprocess_input\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=func_preprocess_input)\n",
    "\n",
    "test_ds = test_datagen.flow_from_directory(\n",
    "    directory=temp_test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGU1SbyGcUoW"
   },
   "outputs": [],
   "source": [
    "file_paths_no_labels = [os.path.join(test_features_dir, f) for f in os.listdir(test_features_dir) if f.lower().endswith('.jpg')]\n",
    "file_paths_no_labels.sort()\n",
    "\n",
    "df_test = pd.DataFrame({'filename': file_paths_no_labels})\n",
    "\n",
    "test_predictions = load_model.predict(test_ds, max_queue_size=14, workers=4)\n",
    "species_labels = sorted(train_labels.columns.unique())\n",
    "test_preds_df = pd.DataFrame(test_predictions, columns=species_labels)\n",
    "test_preds_df.index = [os.path.splitext(os.path.basename(filename))[0] for filename in test_ds.filenames]\n",
    "test_preds_df = test_preds_df.round(6)\n",
    "test_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQh7O1lRcUoX"
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree(temp_test_dir)\n",
    "submission_format = pd.read_csv(os.path.join(dataset_path, 'submission_format.csv'), index_col=\"id\")\n",
    "\n",
    "assert all(test_preds_df.index == submission_format.index)\n",
    "assert all(test_preds_df.columns == submission_format.columns)\n",
    "\n",
    "test_preds_df.to_csv(\"submission_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOAcVDVjvKnd"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyNZ6yekckmaW7JzjR64OeU0",
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
